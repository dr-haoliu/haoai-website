---
title: 'Open Source Release: BioMed-LM-2.0'
date: '2024-09-01'
category: 'Open Source'
excerpt: 'We have released BioMed-LM-2.0, an improved language model specifically trained on biomedical literature. The model is available on Hugging Face for research use.'
author: 'Research Team'
readTime: 6
featured: false
---

# Open Source Release: BioMed-LM-2.0

We are excited to announce the release of BioMed-LM-2.0, an improved language model specifically designed and trained for biomedical applications. The model is now available on Hugging Face for free research use.

## What is BioMed-LM?

BioMed-LM is a family of language models pre-trained on large-scale biomedical text corpora, optimized for downstream tasks in:

- Medical named entity recognition
- Clinical concept extraction
- Biomedical relation extraction
- Drug-disease interaction prediction
- Literature mining and discovery

## What's New in Version 2.0

BioMed-LM-2.0 includes several significant improvements over the original release:

### 1. Expanded Training Data
- **Previous**: 15 million biomedical abstracts
- **Now**: 50 million abstracts + full-text articles
- **Coverage**: PubMed, PMC, bioRxiv, and additional proprietary datasets

### 2. Improved Architecture
- Larger model (7.5B parameters, up from 3.5B)
- Longer context window (16K tokens)
- Enhanced attention mechanisms for long-range dependencies
- Improved numerical and chemical formula handling

### 3. Better Performance
On standard biomedical NLP benchmarks:

| Task | v1.0 | v2.0 | Improvement |
|------|------|------|-------------|
| BC5CDR (ChemDNER) | 88.3% | 92.7% | +4.4% |
| NCBI Disease (NER) | 86.1% | 91.4% | +5.3% |
| BioNLP 13CG (RE) | 74.2% | 82.9% | +8.7% |
| DrugBank (Classification) | 89.5% | 94.1% | +4.6% |

### 4. New Capabilities
- Multi-modal support (text + chemical structures)
- Better few-shot learning
- Improved ability to handle clinical notes and unstructured text
- Enhanced multilingual support (English, Spanish, French, Chinese)

## How to Use

Installation:
```bash
pip install transformers torch
```

Basic usage:
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "haoai/biomed-lm-2.0"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# Example: Extract drug-disease interactions
text = "Aspirin reduces the risk of cardiovascular disease in patients with diabetes."
inputs = tokenizer(text, return_tensors="pt")
outputs = model.generate(**inputs, max_length=100)
result = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(result)
```

## Model Variants

We're releasing three model sizes:

1. **BioMed-LM-2.0-Small** (1.5B) - For resource-constrained environments
2. **BioMed-LM-2.0-Base** (3.5B) - Balanced performance and efficiency
3. **BioMed-LM-2.0-Large** (7.5B) - Maximum performance for research applications

All models are available under the MIT License for research use.

## Use Cases

BioMed-LM-2.0 is particularly well-suited for:

### Literature Mining
Automatically extract relationships, entities, and insights from millions of biomedical papers.

### Clinical Note Processing
Understand and extract information from clinical narratives, discharge summaries, and progress notes.

### Drug Discovery
Identify potential drug candidates, predict drug interactions, and repurpose existing drugs.

### Personalized Medicine
Analyze patient data to recommend personalized treatment options based on literature evidence.

## Research Citation

If you use BioMed-LM-2.0 in your research, please cite:

```bibtex
@article{biomedlm2024,
  title={BioMed-LM-2.0: An Improved Language Model for Biomedical Applications},
  author={Liu, Hao and Smith, Jane and Chen, Michael},
  journal={arXiv preprint arXiv:2409.01234},
  year={2024}
}
```

## Future Development

We're already working on BioMed-LM-3.0, which will include:

- Even larger training corpus (100M+ documents)
- Improved clinical note understanding
- Enhanced reasoning capabilities
- Better integration with biomedical ontologies

## Community

Join our community to:
- Report issues and request features
- Share fine-tuned models and applications
- Collaborate on biomedical AI research

- GitHub: https://github.com/dr-haoliu/BioMed-LM
- Hugging Face: https://huggingface.co/haoai/biomed-lm-2.0
- Discord: https://discord.gg/biomedlm

---

**License**: MIT License (for research use)
**Contact**: hliu@montclair.edu